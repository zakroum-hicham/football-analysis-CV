{"cells":[{"cell_type":"markdown","metadata":{},"source":["## installing libs"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-09-15T18:51:42.411857Z","iopub.status.busy":"2024-09-15T18:51:42.411496Z","iopub.status.idle":"2024-09-15T18:51:55.724173Z","shell.execute_reply":"2024-09-15T18:51:55.723025Z","shell.execute_reply.started":"2024-09-15T18:51:42.411823Z"},"trusted":true},"outputs":[],"source":["!pip install -q ultralytics roboflow"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-09-15T18:51:55.727077Z","iopub.status.busy":"2024-09-15T18:51:55.726664Z","iopub.status.idle":"2024-09-15T18:51:55.732291Z","shell.execute_reply":"2024-09-15T18:51:55.731238Z","shell.execute_reply.started":"2024-09-15T18:51:55.727031Z"},"trusted":true},"outputs":[],"source":["from roboflow import Roboflow"]},{"cell_type":"code","execution_count":27,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2024-09-15T18:51:55.733797Z","iopub.status.busy":"2024-09-15T18:51:55.733456Z","iopub.status.idle":"2024-09-15T18:52:08.157893Z","shell.execute_reply":"2024-09-15T18:52:08.156642Z","shell.execute_reply.started":"2024-09-15T18:51:55.733758Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["^C\n","\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip install -q gdown inference-gpu"]},{"cell_type":"markdown","metadata":{},"source":["## get the key point detection from roboflow"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-09-15T18:52:08.161346Z","iopub.status.busy":"2024-09-15T18:52:08.160919Z","iopub.status.idle":"2024-09-15T18:52:11.655832Z","shell.execute_reply":"2024-09-15T18:52:11.652131Z","shell.execute_reply.started":"2024-09-15T18:52:08.161308Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["UserWarning: Specified provider 'OpenVINOExecutionProvider' is not in available provider names.Available providers: 'TensorrtExecutionProvider, CUDAExecutionProvider, CPUExecutionProvider'\n","2024-09-15 18:52:08.340825833 [W:onnxruntime:Default, onnxruntime_pybind_state.cc:640 CreateExecutionProviderInstance] Failed to create CUDAExecutionProvider. Please reference https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html#requirements to ensure all dependencies are met.\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[28], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minference\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_model\n\u001b[1;32m      2\u001b[0m FIELD_DETECTION_MODEL_ID \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfootball-field-detection-f07vi/14\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m FIELD_DETECTION_MODEL \u001b[38;5;241m=\u001b[39m \u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFIELD_DETECTION_MODEL_ID\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m5lupAJ0ZuQ3Z3DH8ic8g\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/inference/models/utils.py:276\u001b[0m, in \u001b[0;36mget_model\u001b[0;34m(model_id, api_key, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_model\u001b[39m(model_id, api_key\u001b[38;5;241m=\u001b[39mAPI_KEY, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Model:\n\u001b[1;32m    275\u001b[0m     task, model \u001b[38;5;241m=\u001b[39m get_model_type(model_id, api_key\u001b[38;5;241m=\u001b[39mapi_key)\n\u001b[0;32m--> 276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mROBOFLOW_MODEL_TYPES\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/inference/core/models/keypoints_detection_base.py:38\u001b[0m, in \u001b[0;36mKeypointsDetectionBaseOnnxRoboflowInferenceModel.__init__\u001b[0;34m(self, model_id, *args, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_id: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/inference/core/models/roboflow.py:614\u001b[0m, in \u001b[0;36mOnnxRoboflowInferenceModel.__init__\u001b[0;34m(self, model_id, onnxruntime_execution_providers, *args, **kwargs)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_loader_threadpool \u001b[38;5;241m=\u001b[39m ThreadPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 614\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ModelArtefactError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    616\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to validate model artifacts, clearing cache: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/inference/core/models/roboflow.py:656\u001b[0m, in \u001b[0;36mOnnxRoboflowInferenceModel.validate_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    652\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ModelArtefactError(\n\u001b[1;32m    653\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mONNX session not initialized. Check that the model weights are available.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    654\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 656\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_test_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ModelArtefactError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to run test inference. Cause: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/inference/core/models/roboflow.py:670\u001b[0m, in \u001b[0;36mOnnxRoboflowInferenceModel.run_test_inference\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    668\u001b[0m test_image \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m1024\u001b[39m, \u001b[38;5;241m1024\u001b[39m, \u001b[38;5;241m3\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m255\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n\u001b[1;32m    669\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning test inference. Image size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_image\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 670\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musage_inference_test_run\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    671\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest inference finished.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/inference/core/models/object_detection_base.py:76\u001b[0m, in \u001b[0;36mObjectDetectionBaseOnnxRoboflowInferenceModel.infer\u001b[0;34m(self, image, class_agnostic_nms, confidence, disable_preproc_auto_orient, disable_preproc_contrast, disable_preproc_grayscale, disable_preproc_static_crop, iou_threshold, fix_batch_size, max_candidates, max_detections, return_image_dims, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minfer\u001b[39m(\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     36\u001b[0m     image: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     49\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m     50\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03m    Runs object detection inference on one or multiple images and returns the detections.\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m        ValueError: If batching is not enabled for the model and more than one image is passed for processing.\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_agnostic_nms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_agnostic_nms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfidence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfidence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable_preproc_auto_orient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_preproc_auto_orient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable_preproc_contrast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_preproc_contrast\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable_preproc_grayscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_preproc_grayscale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable_preproc_static_crop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_preproc_static_crop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43miou_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miou_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfix_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfix_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_candidates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_candidates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_detections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_detections\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_image_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_image_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/inference/core/models/roboflow.py:628\u001b[0m, in \u001b[0;36mOnnxRoboflowInferenceModel.infer\u001b[0;34m(self, image, **kwargs)\u001b[0m\n\u001b[1;32m    626\u001b[0m max_batch_size \u001b[38;5;241m=\u001b[39m MAX_BATCH_SIZE \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatching_enabled \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (input_elements \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (max_batch_size \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m--> 628\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInference will be executed in batches, as there is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_elements\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m input elements and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximum batch size for a model is set to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_batch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    632\u001b[0m )\n\u001b[1;32m    633\u001b[0m inference_results \u001b[38;5;241m=\u001b[39m []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/inference/usage_tracking/collector.py:606\u001b[0m, in \u001b[0;36mUsageCollector.__call__.<locals>.sync_wrapper\u001b[0;34m(usage_fps, usage_api_key, usage_workflow_id, usage_workflow_preview, usage_inference_test_run, *args, **kwargs)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msync_wrapper\u001b[39m(\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs,\n\u001b[1;32m    593\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecord_usage(\n\u001b[1;32m    595\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extract_usage_params_from_func_kwargs(\n\u001b[1;32m    596\u001b[0m             usage_fps\u001b[38;5;241m=\u001b[39musage_fps,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    604\u001b[0m         )\n\u001b[1;32m    605\u001b[0m     )\n\u001b[0;32m--> 606\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/inference/core/models/base.py:29\u001b[0m, in \u001b[0;36mBaseInference.infer\u001b[0;34m(self, image, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m preproc_image, returned_metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(image, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     26\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreprocessed input shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mgetattr\u001b[39m(preproc_image,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     28\u001b[0m )\n\u001b[0;32m---> 29\u001b[0m predicted_arrays \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreproc_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m postprocessed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(predicted_arrays, returned_metadata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m postprocessed\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/inference/models/yolov8/yolov8_keypoints_detection.py:43\u001b[0m, in \u001b[0;36mYOLOv8KeypointsDetection.predict\u001b[0;34m(self, img_in, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, img_in: np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]:\n\u001b[1;32m     35\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Performs object detection on the given image using the ONNX session.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03m        Tuple[np.ndarray]: NumPy array representing the predictions, including boxes, confidence scores, and class confidence scores.\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_in\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     44\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m predictions\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     45\u001b[0m     boxes \u001b[38;5;241m=\u001b[39m predictions[:, :, :\u001b[38;5;241m4\u001b[39m]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:217\u001b[0m, in \u001b[0;36mSession.run\u001b[0;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[1;32m    215\u001b[0m     output_names \u001b[38;5;241m=\u001b[39m [output\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_meta]\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_feed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m C\u001b[38;5;241m.\u001b[39mEPFail \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_fallback:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from inference import get_model\n","FIELD_DETECTION_MODEL_ID = \"football-field-detection-f07vi/14\"\n","FIELD_DETECTION_MODEL = get_model(model_id=FIELD_DETECTION_MODEL_ID, api_key=\"5lupAJ0ZuQ3Z3DH8ic8g\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:52:11.656497Z","iopub.status.idle":"2024-09-15T18:52:11.656852Z","shell.execute_reply":"2024-09-15T18:52:11.656697Z","shell.execute_reply.started":"2024-09-15T18:52:11.656679Z"},"trusted":true},"outputs":[],"source":["# rf = Roboflow(api_key=\"5lupAJ0ZuQ3Z3DH8ic8g\")\n","\n","# project = rf.workspace(\"wisd-projects\").project(\"football-analysis-pwwi6\")\n","# version = project.version(1)\n","# # dataset = version.download(\"yolov8\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:52:11.658951Z","iopub.status.idle":"2024-09-15T18:52:11.659859Z","shell.execute_reply":"2024-09-15T18:52:11.659610Z","shell.execute_reply.started":"2024-09-15T18:52:11.659573Z"},"trusted":true},"outputs":[],"source":["# !sed -i 's|\\(train: \\).*|\\1../train/images|' {dataset.location}/data.yaml\n","# !sed -i 's|\\(val: \\).*|\\1../valid/images|' {dataset.location}/data.yaml"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:52:11.661086Z","iopub.status.idle":"2024-09-15T18:52:11.661570Z","shell.execute_reply":"2024-09-15T18:52:11.661349Z","shell.execute_reply.started":"2024-09-15T18:52:11.661324Z"},"trusted":true},"outputs":[],"source":["# # import shutil \n","# # shutil.rmtree(\"/kaggle/working/runs\")\n","# import os\n","\n","# # Disable W&B completely\n","# os.environ[\"WANDB_MODE\"] = \"disabled\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:52:11.663006Z","iopub.status.idle":"2024-09-15T18:52:11.663400Z","shell.execute_reply":"2024-09-15T18:52:11.663230Z","shell.execute_reply.started":"2024-09-15T18:52:11.663186Z"},"trusted":true},"outputs":[],"source":["# !yolo task=detect mode=train model=yolov8x.pt data={dataset.location}/data.yaml batch=4 epochs=100 imgsz=1280"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:52:11.664923Z","iopub.status.idle":"2024-09-15T18:52:11.665311Z","shell.execute_reply":"2024-09-15T18:52:11.665117Z","shell.execute_reply.started":"2024-09-15T18:52:11.665099Z"},"trusted":true},"outputs":[],"source":["# !yolo task=detect mode=val model=/kaggle/working/runs/detect/train4/weights/best.pt data={dataset.location}/data.yaml imgsz=1280"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:52:11.666767Z","iopub.status.idle":"2024-09-15T18:52:11.667110Z","shell.execute_reply":"2024-09-15T18:52:11.666959Z","shell.execute_reply.started":"2024-09-15T18:52:11.666941Z"},"trusted":true},"outputs":[],"source":["# !yolo predict model=/kaggle/working/runs/detect/train4/weights/best.pt source=\"/kaggle/input/video1/08fd33_4.mp4\" imgsz=1280 save=True"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:52:11.668014Z","iopub.status.idle":"2024-09-15T18:52:11.668375Z","shell.execute_reply":"2024-09-15T18:52:11.668186Z","shell.execute_reply.started":"2024-09-15T18:52:11.668170Z"},"trusted":true},"outputs":[],"source":["# project.version(1).deploy(model_type=\"yolov8\", model_path=\"/kaggle/working/runs/detect/train4/\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## using the model for detection players,goalkeeper,referee and ball"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:52:11.670355Z","iopub.status.idle":"2024-09-15T18:52:11.670851Z","shell.execute_reply":"2024-09-15T18:52:11.670612Z","shell.execute_reply.started":"2024-09-15T18:52:11.670578Z"},"trusted":true},"outputs":[],"source":["import cv2\n","# get the total number of frames \n","def get_number_of_frames(VIDEO_SRC):\n","    cap = cv2.VideoCapture(VIDEO_SRC)\n","    if not cap.isOpened():\n","        return -1\n","    else:\n","        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","        fps = cap.get(cv2.CAP_PROP_FPS)\n","        return total_frames,fps"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:52:11.672258Z","iopub.status.idle":"2024-09-15T18:52:11.672625Z","shell.execute_reply":"2024-09-15T18:52:11.672462Z","shell.execute_reply.started":"2024-09-15T18:52:11.672444Z"},"trusted":true},"outputs":[],"source":["!pip install -q supervision"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:52:11.674031Z","iopub.status.idle":"2024-09-15T18:52:11.674520Z","shell.execute_reply":"2024-09-15T18:52:11.674293Z","shell.execute_reply.started":"2024-09-15T18:52:11.674268Z"},"trusted":true},"outputs":[],"source":["import cv2\n","import supervision as sv\n","\n","# drawing a rectaggle showing the ball_control percentage for each team\n","def draw_team_ball_control(frame,ball_control,MODEL_CLASSES):\n","        \n","        overlay = frame.copy()\n","        cv2.rectangle(overlay, (1210, 145), (1838,70), (255,255,255), -1 )\n","        alpha = 0.6\n","        cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0, frame)\n","\n","        team_1 = ball_control[MODEL_CLASSES[\"team1\"]] / (ball_control[MODEL_CLASSES[\"team1\"]]+ball_control[MODEL_CLASSES[\"team2\"]])\n","        team_2 = ball_control[MODEL_CLASSES[\"team2\"]] / (ball_control[MODEL_CLASSES[\"team1\"]]+ball_control[MODEL_CLASSES[\"team2\"]])\n","\n","        cv2.putText(frame,\"Ball Control : \",(1220,115),cv2.FONT_HERSHEY_DUPLEX, 1,(0,0,0),3)\n","        cv2.putText(frame, f\"{team_1*100:.2f}%\",(1500,115), cv2.FONT_HERSHEY_SIMPLEX, 1, sv.Color.as_bgr(sv.Color.from_hex('#1E90FF')), 3)\n","        cv2.putText(frame, f\"{team_2*100:.2f}%\",(1700,115), cv2.FONT_HERSHEY_SIMPLEX, 1, sv.Color.as_bgr(sv.Color.from_hex('#DC143C')), 3)\n","\n","        return frame"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:52:11.676086Z","iopub.status.idle":"2024-09-15T18:52:11.676580Z","shell.execute_reply":"2024-09-15T18:52:11.676349Z","shell.execute_reply.started":"2024-09-15T18:52:11.676325Z"},"trusted":true},"outputs":[],"source":["# making some custem annotations\n","\n","import supervision as sv\n","\n","colors = {\n","    \"team1\":sv.ColorPalette.from_hex(['#1E90FF']),\n","    \"team2\":sv.ColorPalette.from_hex(['#DC143C']),\n","    \"referee\":sv.ColorPalette.from_hex(['#FFD700']),\n","    \"goalkepper\":sv.ColorPalette.from_hex(['#FFF']),\n","    \"label_text\":sv.Color.from_hex('#000'),\n","    \"ball\":sv.Color.from_hex('#FF8C00'),\n","    \"active_player\":sv.Color.from_rgb_tuple((255,0,0))\n","}\n","\n","LABEL_TEXT_POSITION = sv.Position.BOTTOM_CENTER\n","\n","\n","team1_ellipse_annotator = sv.EllipseAnnotator(color=colors[\"team1\"])  \n","team2_ellipse_annotator = sv.EllipseAnnotator(color=colors['team2'])\n","referee_ellipse_annotator = sv.EllipseAnnotator(color=colors['referee'])\n","goalkepper_ellipse_annotator = sv.EllipseAnnotator(color=colors['goalkepper'])\n","active_player_annotator = sv.TriangleAnnotator(color=colors['active_player'],base=18,height=18)\n","\n","team1_label_annotator = sv.LabelAnnotator(color=colors['team1'],text_color=colors['label_text'], text_position=LABEL_TEXT_POSITION)\n","team2_label_annotator = sv.LabelAnnotator(color=colors['team2'],text_color=colors['label_text'],text_position=LABEL_TEXT_POSITION)\n","referee_label_annotator = sv.LabelAnnotator(color=colors['referee'],text_color=colors['label_text'],border_radius=30, text_position=LABEL_TEXT_POSITION)\n","goalkepper_label_annotator = sv.LabelAnnotator(color=colors['goalkepper'],text_color=colors['label_text'],border_radius=30,text_position=LABEL_TEXT_POSITION)\n","\n","ball_triangle_annotator = sv.TriangleAnnotator(color=colors['ball'], base=18, height=18)\n","\n","\n","# annotate the frames\n","def annotate_frames(frame,all_detection,labels,ball_posession,MODEL_CLASSES):\n","    annotated_frame = frame.copy()\n","    annotated_frame = team1_ellipse_annotator.annotate(scene=annotated_frame, detections=all_detection[\"team1\"])\n","    annotated_frame = team2_ellipse_annotator.annotate(scene=annotated_frame, detections=all_detection[\"team2\"])\n","    annotated_frame = referee_ellipse_annotator.annotate(scene=annotated_frame, detections=all_detection[\"referee\"])\n","    annotated_frame = goalkepper_ellipse_annotator.annotate(scene=annotated_frame,detections=all_detection[\"goalkeepers\"])\n","    annotated_frame = ball_triangle_annotator.annotate(scene=annotated_frame, detections=all_detection[\"ball\"])\n","    annotated_frame = team1_label_annotator.annotate(scene=annotated_frame, detections=all_detection[\"team1\"], labels=labels[\"labels_team1\"])\n","    annotated_frame = team2_label_annotator.annotate(scene=annotated_frame, detections=all_detection[\"team2\"], labels=labels[\"labels_team2\"])\n","    annotated_frame = referee_label_annotator.annotate(scene=annotated_frame,detections=all_detection[\"referee\"],labels=labels[\"labels_referee\"])\n","    annotated_frame = goalkepper_label_annotator.annotate(scene=annotated_frame,detections=all_detection[\"goalkeepers\"],labels=labels[\"labels_gk\"])\n","    annotated_frame = active_player_annotator.annotate(scene=annotated_frame,detections=all_detection[\"active_player\"]) \n","    annotated_frame = draw_team_ball_control(annotated_frame,ball_posession,MODEL_CLASSES)\n","    return annotated_frame"]},{"cell_type":"markdown","metadata":{},"source":["###  team assigner"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:52:11.678244Z","iopub.status.idle":"2024-09-15T18:52:11.678715Z","shell.execute_reply":"2024-09-15T18:52:11.678492Z","shell.execute_reply.started":"2024-09-15T18:52:11.678467Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from sklearn.cluster import KMeans\n","import supervision as sv\n","import numpy as np\n","from PIL import Image,ImageOps\n","import cv2\n","class Assigner:\n","    def __init__(self) -> None:\n","         self.team_colors={}\n","\n","    def get_clustering_model(self,image):\n","        image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n","        image_2d = image.reshape(-1,3)\n","        # Preform K-means with 2 clusters\n","        kmeans = KMeans(n_clusters=2,n_init=1)\n","        kmeans.fit(image_2d)\n","\n","        return kmeans\n","\n","    def get_player_team(self,frame, player_bbox,kmeans):\n","            player_color = self.get_player_color(frame, player_bbox)\n","            team_id = kmeans.predict(player_color.reshape(1, -1))[0]\n","            return team_id\n","\n","    def get_player_color(self,frame, bbox):\n","        image = frame[int(bbox[1]):int(bbox[3]), int(bbox[0]):int(bbox[2])]\n","        top_half_image = image[0:int(image.shape[0] / 2), :]\n","        kmeans = self.get_clustering_model(top_half_image)\n","        labels = kmeans.labels_\n","\n","        clustered_image = labels.reshape(top_half_image.shape[0], top_half_image.shape[1])\n","        corner_clusters = [clustered_image[0, 0], clustered_image[0, -1], clustered_image[-1, 0], clustered_image[-1, -1]]\n","        non_player_cluster = max(set(corner_clusters), key=corner_clusters.count)\n","        player_cluster = 1 - non_player_cluster\n","        player_color = kmeans.cluster_centers_[player_cluster]\n","\n","        # centriod = kmeans.cluster_centers_\n","        # percent = []\n","        # labels = list(labels)\n","        # for i in range(len(centriod)):\n","        #      j = labels.count(i)\n","        #      j/=len(labels)\n","        #      percent.append(j)\n","        \n","        # plt.pie(percent,colors=np.array(centriod/255),labels=np.arange(len(centriod)))\n","        \n","        # plt.show()\n","        # print(player_cluster)\n","        # sv.plot_image(clustered_image)\n","        return player_color\n","\n","    def assign_team_color(self,frame, players_detections):\n","            \n","            player_colors = []\n","            for xy2 in players_detections.xyxy:\n","                bbox = xy2\n","                player_color = self.get_player_color(frame, bbox)\n","                player_colors.append(player_color)\n","            \n","            kmeans = KMeans(n_clusters=2, init=\"k-means++\", n_init=\"auto\")\n","            kmeans.fit(player_colors)\n","            self.team_colors[1] = kmeans.cluster_centers_[0]\n","            self.team_colors[2] = kmeans.cluster_centers_[1]\n","            return kmeans"]},{"cell_type":"markdown","metadata":{},"source":["### assign the ball to a player"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:52:11.680886Z","iopub.status.idle":"2024-09-15T18:52:11.681375Z","shell.execute_reply":"2024-09-15T18:52:11.681132Z","shell.execute_reply.started":"2024-09-15T18:52:11.681108Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","\n","\n","MAX_DISTANCE = 70\n","    \n","\n","def get_center_of_bbox(bbox):\n","    x1,y1,x2,y2 = bbox\n","    return int((x1+x2)/2),int((y1+y2)/2)\n","\n","def measure_distance(p1,p2):\n","    return np.sqrt((p1[0]-p2[0])**2 + (p1[1]-p2[1])**2)\n","\n","\n","def assign_ball_to_player(players_detections,ball_bbox):\n","    if len(ball_bbox)==0 or len(players_detections.xyxy) == 0:\n","        return -1\n","    ball_position = get_center_of_bbox(ball_bbox[0])\n","\n","    miniumum_distance = 99999\n","    assigned_player=-1\n","\n","    for object_ind , _ in enumerate(players_detections.class_id):\n","        player_bbox = players_detections.xyxy[object_ind]\n","\n","        distance_left = measure_distance((player_bbox[0],player_bbox[-1]),ball_position)\n","        distance_right = measure_distance((player_bbox[2],player_bbox[-1]),ball_position)\n","        distance = min(distance_left,distance_right)\n","\n","        if distance < MAX_DISTANCE:\n","            if distance < miniumum_distance:\n","                miniumum_distance = distance\n","                assigned_player = object_ind\n","\n","    return assigned_player"]},{"cell_type":"markdown","metadata":{},"source":["### this code is from the roboflow repo link -> https://github.com/roboflow/sports "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:52:11.682943Z","iopub.status.idle":"2024-09-15T18:52:11.683307Z","shell.execute_reply":"2024-09-15T18:52:11.683124Z","shell.execute_reply.started":"2024-09-15T18:52:11.683107Z"},"trusted":true},"outputs":[],"source":["from dataclasses import dataclass, field\n","from typing import List, Tuple\n","\n","\n","@dataclass\n","class SoccerPitchConfiguration:\n","    width: int = 7000  # [cm]\n","    length: int = 12000  # [cm]\n","    penalty_box_width: int = 4100  # [cm]\n","    penalty_box_length: int = 2015  # [cm]\n","    goal_box_width: int = 1832  # [cm]\n","    goal_box_length: int = 550  # [cm]\n","    centre_circle_radius: int = 915  # [cm]\n","    penalty_spot_distance: int = 1100  # [cm]\n","\n","    @property\n","    def vertices(self) -> List[Tuple[int, int]]:\n","        return [\n","            (0, 0),  # 1\n","            (0, (self.width - self.penalty_box_width) / 2),  # 2\n","            (0, (self.width - self.goal_box_width) / 2),  # 3\n","            (0, (self.width + self.goal_box_width) / 2),  # 4\n","            (0, (self.width + self.penalty_box_width) / 2),  # 5\n","            (0, self.width),  # 6\n","            (self.goal_box_length, (self.width - self.goal_box_width) / 2),  # 7\n","            (self.goal_box_length, (self.width + self.goal_box_width) / 2),  # 8\n","            (self.penalty_spot_distance, self.width / 2),  # 9\n","            (self.penalty_box_length, (self.width - self.penalty_box_width) / 2),  # 10\n","            (self.penalty_box_length, (self.width - self.goal_box_width) / 2),  # 11\n","            (self.penalty_box_length, (self.width + self.goal_box_width) / 2),  # 12\n","            (self.penalty_box_length, (self.width + self.penalty_box_width) / 2),  # 13\n","            (self.length / 2, 0),  # 14\n","            (self.length / 2, self.width / 2 - self.centre_circle_radius),  # 15\n","            (self.length / 2, self.width / 2 + self.centre_circle_radius),  # 16\n","            (self.length / 2, self.width),  # 17\n","            (\n","                self.length - self.penalty_box_length,\n","                (self.width - self.penalty_box_width) / 2\n","            ),  # 18\n","            (\n","                self.length - self.penalty_box_length,\n","                (self.width - self.goal_box_width) / 2\n","            ),  # 19\n","            (\n","                self.length - self.penalty_box_length,\n","                (self.width + self.goal_box_width) / 2\n","            ),  # 20\n","            (\n","                self.length - self.penalty_box_length,\n","                (self.width + self.penalty_box_width) / 2\n","            ),  # 21\n","            (self.length - self.penalty_spot_distance, self.width / 2),  # 22\n","            (\n","                self.length - self.goal_box_length,\n","                (self.width - self.goal_box_width) / 2\n","            ),  # 23\n","            (\n","                self.length - self.goal_box_length,\n","                (self.width + self.goal_box_width) / 2\n","            ),  # 24\n","            (self.length, 0),  # 25\n","            (self.length, (self.width - self.penalty_box_width) / 2),  # 26\n","            (self.length, (self.width - self.goal_box_width) / 2),  # 27\n","            (self.length, (self.width + self.goal_box_width) / 2),  # 28\n","            (self.length, (self.width + self.penalty_box_width) / 2),  # 29\n","            (self.length, self.width),  # 30\n","            (self.length / 2 - self.centre_circle_radius, self.width / 2),  # 31\n","            (self.length / 2 + self.centre_circle_radius, self.width / 2),  # 32\n","        ]\n","\n","    edges: List[Tuple[int, int]] = field(default_factory=lambda: [\n","        (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (7, 8),\n","        (10, 11), (11, 12), (12, 13), (14, 15), (15, 16),\n","        (16, 17), (18, 19), (19, 20), (20, 21), (23, 24),\n","        (25, 26), (26, 27), (27, 28), (28, 29), (29, 30),\n","        (1, 14), (2, 10), (3, 7), (4, 8), (5, 13), (6, 17),\n","        (14, 25), (18, 26), (23, 27), (24, 28), (21, 29), (17, 30)\n","    ])\n","\n","    labels: List[str] = field(default_factory=lambda: [\n","        \"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\",\n","        \"11\", \"12\", \"13\", \"15\", \"16\", \"17\", \"18\", \"20\", \"21\", \"22\",\n","        \"23\", \"24\", \"25\", \"26\", \"27\", \"28\", \"29\", \"30\", \"31\", \"32\",\n","        \"14\", \"19\"\n","    ])\n","\n","    colors: List[str] = field(default_factory=lambda: [\n","        \"#FF1493\", \"#FF1493\", \"#FF1493\", \"#FF1493\", \"#FF1493\", \"#FF1493\",\n","        \"#FF1493\", \"#FF1493\", \"#FF1493\", \"#FF1493\", \"#FF1493\", \"#FF1493\",\n","        \"#FF1493\", \"#00BFFF\", \"#00BFFF\", \"#00BFFF\", \"#00BFFF\", \"#FF6347\",\n","        \"#FF6347\", \"#FF6347\", \"#FF6347\", \"#FF6347\", \"#FF6347\", \"#FF6347\",\n","        \"#FF6347\", \"#FF6347\", \"#FF6347\", \"#FF6347\", \"#FF6347\", \"#FF6347\",\n","        \"#00BFFF\", \"#00BFFF\"\n","    ])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:52:11.684518Z","iopub.status.idle":"2024-09-15T18:52:11.684880Z","shell.execute_reply":"2024-09-15T18:52:11.684723Z","shell.execute_reply.started":"2024-09-15T18:52:11.684704Z"},"trusted":true},"outputs":[],"source":["from typing import Optional, List\n","\n","import cv2\n","import supervision as sv\n","import numpy as np\n","\n","\n","\n","def draw_pitch(\n","    config: SoccerPitchConfiguration,\n","    background_color: sv.Color = sv.Color(34, 139, 34),\n","    line_color: sv.Color = sv.Color.WHITE,\n","    padding: int = 50,\n","    line_thickness: int = 4,\n","    point_radius: int = 8,\n","    scale: float = 0.1\n",") -> np.ndarray:\n","    \"\"\"\n","    Draws a soccer pitch with specified dimensions, colors, and scale.\n","\n","    Args:\n","        config (SoccerPitchConfiguration): Configuration object containing the\n","            dimensions and layout of the pitch.\n","        background_color (sv.Color, optional): Color of the pitch background.\n","            Defaults to sv.Color(34, 139, 34).\n","        line_color (sv.Color, optional): Color of the pitch lines.\n","            Defaults to sv.Color.WHITE.\n","        padding (int, optional): Padding around the pitch in pixels.\n","            Defaults to 50.\n","        line_thickness (int, optional): Thickness of the pitch lines in pixels.\n","            Defaults to 4.\n","        point_radius (int, optional): Radius of the penalty spot points in pixels.\n","            Defaults to 8.\n","        scale (float, optional): Scaling factor for the pitch dimensions.\n","            Defaults to 0.1.\n","\n","    Returns:\n","        np.ndarray: Image of the soccer pitch.\n","    \"\"\"\n","    scaled_width = int(config.width * scale)\n","    scaled_length = int(config.length * scale)\n","    scaled_circle_radius = int(config.centre_circle_radius * scale)\n","    scaled_penalty_spot_distance = int(config.penalty_spot_distance * scale)\n","\n","    pitch_image = np.ones(\n","        (scaled_width + 2 * padding,\n","         scaled_length + 2 * padding, 3),\n","        dtype=np.uint8\n","    ) * np.array(background_color.as_bgr(), dtype=np.uint8)\n","\n","    for start, end in config.edges:\n","        point1 = (int(config.vertices[start - 1][0] * scale) + padding,\n","                  int(config.vertices[start - 1][1] * scale) + padding)\n","        point2 = (int(config.vertices[end - 1][0] * scale) + padding,\n","                  int(config.vertices[end - 1][1] * scale) + padding)\n","        cv2.line(\n","            img=pitch_image,\n","            pt1=point1,\n","            pt2=point2,\n","            color=line_color.as_bgr(),\n","            thickness=line_thickness\n","        )\n","\n","    centre_circle_center = (\n","        scaled_length // 2 + padding,\n","        scaled_width // 2 + padding\n","    )\n","    cv2.circle(\n","        img=pitch_image,\n","        center=centre_circle_center,\n","        radius=scaled_circle_radius,\n","        color=line_color.as_bgr(),\n","        thickness=line_thickness\n","    )\n","\n","    penalty_spots = [\n","        (\n","            scaled_penalty_spot_distance + padding,\n","            scaled_width // 2 + padding\n","        ),\n","        (\n","            scaled_length - scaled_penalty_spot_distance + padding,\n","            scaled_width // 2 + padding\n","        )\n","    ]\n","    for spot in penalty_spots:\n","        cv2.circle(\n","            img=pitch_image,\n","            center=spot,\n","            radius=point_radius,\n","            color=line_color.as_bgr(),\n","            thickness=-1\n","        )\n","\n","    return pitch_image\n","\n","\n","def draw_points_on_pitch(\n","    config: SoccerPitchConfiguration,\n","    xy: np.ndarray,\n","    face_color: sv.Color = sv.Color.RED,\n","    edge_color: sv.Color = sv.Color.BLACK,\n","    radius: int = 10,\n","    thickness: int = 2,\n","    padding: int = 50,\n","    scale: float = 0.1,\n","    pitch: Optional[np.ndarray] = None\n",") -> np.ndarray:\n","    \"\"\"\n","    Draws points on a soccer pitch.\n","\n","    Args:\n","        config (SoccerPitchConfiguration): Configuration object containing the\n","            dimensions and layout of the pitch.\n","        xy (np.ndarray): Array of points to be drawn, with each point represented by\n","            its (x, y) coordinates.\n","        face_color (sv.Color, optional): Color of the point faces.\n","            Defaults to sv.Color.RED.\n","        edge_color (sv.Color, optional): Color of the point edges.\n","            Defaults to sv.Color.BLACK.\n","        radius (int, optional): Radius of the points in pixels.\n","            Defaults to 10.\n","        thickness (int, optional): Thickness of the point edges in pixels.\n","            Defaults to 2.\n","        padding (int, optional): Padding around the pitch in pixels.\n","            Defaults to 50.\n","        scale (float, optional): Scaling factor for the pitch dimensions.\n","            Defaults to 0.1.\n","        pitch (Optional[np.ndarray], optional): Existing pitch image to draw points on.\n","            If None, a new pitch will be created. Defaults to None.\n","\n","    Returns:\n","        np.ndarray: Image of the soccer pitch with points drawn on it.\n","    \"\"\"\n","    if pitch is None:\n","        pitch = draw_pitch(\n","            config=config,\n","            padding=padding,\n","            scale=scale\n","        )\n","\n","    for point in xy:\n","        scaled_point = (\n","            int(point[0] * scale) + padding,\n","            int(point[1] * scale) + padding\n","        )\n","        cv2.circle(\n","            img=pitch,\n","            center=scaled_point,\n","            radius=radius,\n","            color=face_color.as_bgr(),\n","            thickness=-1\n","        )\n","        cv2.circle(\n","            img=pitch,\n","            center=scaled_point,\n","            radius=radius,\n","            color=edge_color.as_bgr(),\n","            thickness=thickness\n","        )\n","\n","    return pitch\n","\n","\n","def draw_paths_on_pitch(\n","    config: SoccerPitchConfiguration,\n","    paths: List[np.ndarray],\n","    color: sv.Color = sv.Color.WHITE,\n","    thickness: int = 2,\n","    padding: int = 50,\n","    scale: float = 0.1,\n","    pitch: Optional[np.ndarray] = None\n",") -> np.ndarray:\n","    \"\"\"\n","    Draws paths on a soccer pitch.\n","\n","    Args:\n","        config (SoccerPitchConfiguration): Configuration object containing the\n","            dimensions and layout of the pitch.\n","        paths (List[np.ndarray]): List of paths, where each path is an array of (x, y)\n","            coordinates.\n","        color (sv.Color, optional): Color of the paths.\n","            Defaults to sv.Color.WHITE.\n","        thickness (int, optional): Thickness of the paths in pixels.\n","            Defaults to 2.\n","        padding (int, optional): Padding around the pitch in pixels.\n","            Defaults to 50.\n","        scale (float, optional): Scaling factor for the pitch dimensions.\n","            Defaults to 0.1.\n","        pitch (Optional[np.ndarray], optional): Existing pitch image to draw paths on.\n","            If None, a new pitch will be created. Defaults to None.\n","\n","    Returns:\n","        np.ndarray: Image of the soccer pitch with paths drawn on it.\n","    \"\"\"\n","    if pitch is None:\n","        pitch = draw_pitch(\n","            config=config,\n","            padding=padding,\n","            scale=scale\n","        )\n","\n","    for path in paths:\n","        scaled_path = [\n","            (\n","                int(point[0] * scale) + padding,\n","                int(point[1] * scale) + padding\n","            )\n","            for point in path if point.size > 0\n","        ]\n","\n","        if len(scaled_path) < 2:\n","            continue\n","\n","        for i in range(len(scaled_path) - 1):\n","            cv2.line(\n","                img=pitch,\n","                pt1=scaled_path[i],\n","                pt2=scaled_path[i + 1],\n","                color=color.as_bgr(),\n","                thickness=thickness\n","            )\n","\n","        return pitch\n","\n","\n","def draw_pitch_voronoi_diagram(\n","    config: SoccerPitchConfiguration,\n","    team_1_xy: np.ndarray,\n","    team_2_xy: np.ndarray,\n","    team_1_color: sv.Color = sv.Color.RED,\n","    team_2_color: sv.Color = sv.Color.WHITE,\n","    opacity: float = 0.5,\n","    padding: int = 50,\n","    scale: float = 0.1,\n","    pitch: Optional[np.ndarray] = None\n",") -> np.ndarray:\n","    \"\"\"\n","    Draws a Voronoi diagram on a soccer pitch representing the control areas of two\n","    teams.\n","\n","    Args:\n","        config (SoccerPitchConfiguration): Configuration object containing the\n","            dimensions and layout of the pitch.\n","        team_1_xy (np.ndarray): Array of (x, y) coordinates representing the positions\n","            of players in team 1.\n","        team_2_xy (np.ndarray): Array of (x, y) coordinates representing the positions\n","            of players in team 2.\n","        team_1_color (sv.Color, optional): Color representing the control area of\n","            team 1. Defaults to sv.Color.RED.\n","        team_2_color (sv.Color, optional): Color representing the control area of\n","            team 2. Defaults to sv.Color.WHITE.\n","        opacity (float, optional): Opacity of the Voronoi diagram overlay.\n","            Defaults to 0.5.\n","        padding (int, optional): Padding around the pitch in pixels.\n","            Defaults to 50.\n","        scale (float, optional): Scaling factor for the pitch dimensions.\n","            Defaults to 0.1.\n","        pitch (Optional[np.ndarray], optional): Existing pitch image to draw the\n","            Voronoi diagram on. If None, a new pitch will be created. Defaults to None.\n","\n","    Returns:\n","        np.ndarray: Image of the soccer pitch with the Voronoi diagram overlay.\n","    \"\"\"\n","    if pitch is None:\n","        pitch = draw_pitch(\n","            config=config,\n","            padding=padding,\n","            scale=scale\n","        )\n","\n","    scaled_width = int(config.width * scale)\n","    scaled_length = int(config.length * scale)\n","\n","    voronoi = np.zeros_like(pitch, dtype=np.uint8)\n","\n","    team_1_color_bgr = np.array(team_1_color.as_bgr(), dtype=np.uint8)\n","    team_2_color_bgr = np.array(team_2_color.as_bgr(), dtype=np.uint8)\n","\n","    y_coordinates, x_coordinates = np.indices((\n","        scaled_width + 2 * padding,\n","        scaled_length + 2 * padding\n","    ))\n","\n","    y_coordinates -= padding\n","    x_coordinates -= padding\n","\n","    def calculate_distances(xy, x_coordinates, y_coordinates):\n","        return np.sqrt((xy[:, 0][:, None, None] * scale - x_coordinates) ** 2 +\n","                       (xy[:, 1][:, None, None] * scale - y_coordinates) ** 2)\n","\n","    distances_team_1 = calculate_distances(team_1_xy, x_coordinates, y_coordinates)\n","    distances_team_2 = calculate_distances(team_2_xy, x_coordinates, y_coordinates)\n","\n","    min_distances_team_1 = np.min(distances_team_1, axis=0)\n","    min_distances_team_2 = np.min(distances_team_2, axis=0)\n","\n","    control_mask = min_distances_team_1 < min_distances_team_2\n","\n","    voronoi[control_mask] = team_1_color_bgr\n","    voronoi[~control_mask] = team_2_color_bgr\n","\n","    overlay = cv2.addWeighted(voronoi, opacity, pitch, 1 - opacity, 0)\n","\n","    return overlay\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:52:11.686705Z","iopub.status.idle":"2024-09-15T18:52:11.687168Z","shell.execute_reply":"2024-09-15T18:52:11.686950Z","shell.execute_reply.started":"2024-09-15T18:52:11.686925Z"},"trusted":true},"outputs":[],"source":["from typing import Tuple\n","import cv2\n","import numpy as np\n","import numpy.typing as npt\n","\n","\n","class ViewTransformer:\n","    def __init__(\n","            self,\n","            source: npt.NDArray[np.float32],\n","            target: npt.NDArray[np.float32]\n","    ) -> None:\n","        \"\"\"\n","        Initialize the ViewTransformer with source and target points.\n","\n","        Args:\n","            source (npt.NDArray[np.float32]): Source points for homography calculation.\n","            target (npt.NDArray[np.float32]): Target points for homography calculation.\n","\n","        Raises:\n","            ValueError: If source and target do not have the same shape or if they are\n","                not 2D coordinates.\n","        \"\"\"\n","        if source.shape != target.shape:\n","            raise ValueError(\"Source and target must have the same shape.\")\n","        if source.shape[1] != 2:\n","            raise ValueError(\"Source and target points must be 2D coordinates.\")\n","\n","        source = source.astype(np.float32)\n","        target = target.astype(np.float32)\n","        self.m, _ = cv2.findHomography(source, target)\n","        if self.m is None:\n","            raise ValueError(\"Homography matrix could not be calculated.\")\n","\n","    def transform_points(\n","            self,\n","            points: npt.NDArray[np.float32]\n","    ) -> npt.NDArray[np.float32]:\n","        \"\"\"\n","        Transform the given points using the homography matrix.\n","\n","        Args:\n","            points (npt.NDArray[np.float32]): Points to be transformed.\n","\n","        Returns:\n","            npt.NDArray[np.float32]: Transformed points.\n","\n","        Raises:\n","            ValueError: If points are not 2D coordinates.\n","        \"\"\"\n","        if points.size == 0:\n","            return points\n","\n","        if points.shape[1] != 2:\n","            raise ValueError(\"Points must be 2D coordinates.\")\n","\n","        reshaped_points = points.reshape(-1, 1, 2).astype(np.float32)\n","        transformed_points = cv2.perspectiveTransform(reshaped_points, self.m)\n","        return transformed_points.reshape(-1, 2).astype(np.float32)\n","\n","    def transform_image(\n","            self,\n","            image: npt.NDArray[np.uint8],\n","            resolution_wh: Tuple[int, int]\n","    ) -> npt.NDArray[np.uint8]:\n","        \"\"\"\n","        Transform the given image using the homography matrix.\n","\n","        Args:\n","            image (npt.NDArray[np.uint8]): Image to be transformed.\n","            resolution_wh (Tuple[int, int]): Width and height of the output image.\n","\n","        Returns:\n","            npt.NDArray[np.uint8]: Transformed image.\n","\n","        Raises:\n","            ValueError: If the image is not either grayscale or color.\n","        \"\"\"\n","        if len(image.shape) not in {2, 3}:\n","            raise ValueError(\"Image must be either grayscale or color.\")\n","        return cv2.warpPerspective(image, self.m, resolution_wh)\n"]},{"cell_type":"markdown","metadata":{},"source":["### main "]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-09-15T18:52:31.956998Z","iopub.status.busy":"2024-09-15T18:52:31.956512Z","iopub.status.idle":"2024-09-15T19:11:58.758125Z","shell.execute_reply":"2024-09-15T19:11:58.757015Z","shell.execute_reply.started":"2024-09-15T18:52:31.956949Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|| 749/750 [19:26<00:01,  1.56s/it]"]},{"name":"stdout","output_type":"stream","text":["Video saved as /kaggle/working/08fd33_4_output.mp4\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["import numpy as np\n","from ultralytics import YOLO\n","import supervision as sv\n","import cv2\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","import pickle\n","\n","# static variables\n","VIDEO_SRC = \"/kaggle/input/video1/08fd33_4.mp4\"\n","OUT_VIDEO = \"/kaggle/working/08fd33_4_output.mp4\" \n","MODEL_SRC = \"/kaggle/working/runs/detect/train4/weights/best.pt\"\n","MODEL_CLASSES = {\n","     \"ball\":0,\n","     \"goalkepper\":1,\n","     \"player\":2,\n","     \"referee\":3,\n","     \"team1\":4,\n","     \"team2\":5,\n","     \"active_player\":6\n","}\n","\n","CONFIG = SoccerPitchConfiguration()\n","\n","def main():\n","    model = YOLO(MODEL_SRC)\n","    \n","    # get the total frames\n","    total_frames , fps = get_number_of_frames(VIDEO_SRC)\n","\n","    frame_generator = sv.get_video_frames_generator(VIDEO_SRC)\n","\n","    # Get the first frame to determine the video dimensions\n","    first_frame = next(frame_generator)\n","    height, width, _ = first_frame.shape\n","\n","    # Initialize the video writer\n","    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n","    out = cv2.VideoWriter(OUT_VIDEO, fourcc, fps, (width, height+800))\n","    \n","    # \n","    tracker = sv.ByteTrack()\n","    tracker.reset()\n","    tracker1 = sv.ByteTrack()\n","    tracker1.reset()\n","\n","\n","    # Process each frame in the video\n","    is_first_frame = True\n","    class_id_active_player = None\n","    kmeans = None\n","    ball_posession = {MODEL_CLASSES[\"team1\"]:0,MODEL_CLASSES[\"team2\"]:0}\n","    team_colors={}\n","    ########################## for debuging\n","    i = 1\n","    ##########################\n"," \n","    for frame in tqdm(frame_generator,total=total_frames):\n","        \n","        # try:\n","            # Predict the boxes with the model\n","            result = model.predict(frame, conf=0.3,verbose=False)[0]\n","            detections = sv.Detections.from_ultralytics(result)\n","            \n","            # \n","            goalkeepers_detections = detections[detections.class_id == MODEL_CLASSES[\"goalkepper\"]]\n","            \n","            # convert goalkeeper to player\n","#             for object_ind , class_id in enumerate(detections.class_id):\n","#                 if class_id == MODEL_CLASSES[\"goalkepper\"]:\n","#                     detections.class_id[object_ind] = MODEL_CLASSES[\"player\"]\n","\n","            ball_detections = detections[detections.class_id == MODEL_CLASSES[\"ball\"]]\n","            players_detections = detections[detections.class_id == MODEL_CLASSES[\"player\"]]\n","            referee_detections = detections[detections.class_id == MODEL_CLASSES[\"referee\"]]\n","\n","\n","            # Appling Non-Maximum Suppression (NMS) to the players detections\n","            players_detections = players_detections.with_nms(threshold=0.5)\n","            \n","            # Assign Player Teams\n","            if is_first_frame:\n","                team_assigner = Assigner()\n","                kmeans = team_assigner.assign_team_color(frame, players_detections)\n","                team_colors = team_assigner.team_colors\n","                is_first_frame = False\n","            for object_ind , _ in enumerate(players_detections.class_id):\n","                player_color = team_assigner.get_player_color(frame,players_detections.xyxy[object_ind])\n","                team_id = team_assigner.get_player_team(frame, players_detections.xyxy[object_ind],kmeans)\n","                if team_id == 0:\n","                    players_detections.class_id[object_ind] = MODEL_CLASSES[\"team1\"]\n","                    a = np.sqrt((player_color[0] - team_colors[1][0])**2 + (player_color[1] - team_colors[1][1])**2 + (player_color[2]- team_colors[1][2])**2)\n","                    if a > 110 and a < 180:\n","                        players_detections.class_id[object_ind] = MODEL_CLASSES[\"goalkepper\"]\n","                elif team_id == 1:\n","                    players_detections.class_id[object_ind] = MODEL_CLASSES[\"team2\"]\n","                    a = np.sqrt((player_color[0] - team_colors[2][0])**2 + (player_color[1] - team_colors[2][1])**2 + (player_color[2] - team_colors[2][2])**2)\n","                    if a > 110 and a < 180:\n","                        players_detections.class_id[object_ind] = MODEL_CLASSES[\"goalkepper\"]\n","            \n","            \n","            goalkeepers_detections1 = players_detections[players_detections.class_id == MODEL_CLASSES[\"goalkepper\"]]\n","            goalkeepers_detections = sv.Detections.merge([goalkeepers_detections,goalkeepers_detections1])\n","            \n","            team1_detections =  players_detections[players_detections.class_id == MODEL_CLASSES[\"team1\"] ]\n","            team2_detections =  players_detections[players_detections.class_id == MODEL_CLASSES[\"team2\"] ]\n","           \n","            \n","            players_detections = players_detections[players_detections.class_id != MODEL_CLASSES[\"goalkepper\"]]\n","            # assign the ball to the closest player\n","            player_ind = assign_ball_to_player(players_detections,ball_detections.xyxy)\n","            all_players = players_detections\n","            if player_ind != -1:\n","                class_id_active_player = players_detections.class_id[player_ind]\n","                ball_posession[class_id_active_player]+=1\n","                all_players.class_id[player_ind] = MODEL_CLASSES[\"active_player\"]\n","            elif class_id_active_player:\n","                ball_posession[class_id_active_player]+=1\n","            active_player_detection = all_players[all_players.class_id == MODEL_CLASSES[\"active_player\"]]\n","\n","            #  adding a padding to the ball detection and active player\n","            ball_detections.xyxy = sv.pad_boxes(xyxy=ball_detections.xyxy, px=10)\n","            active_player_detection.xyxy = sv.pad_boxes(xyxy=active_player_detection.xyxy, px=10)\n","\n","            # add tracker teams\n","            team1_detections = tracker.update_with_detections(detections=team1_detections)\n","            team2_detections = tracker1.update_with_detections(detections=team2_detections)\n","            \n","            \n","            # creating labels \n","\n","            labels = {\n","                \"labels_team1\" :[f\"{tracker_id}\" for tracker_id in team1_detections.tracker_id],\n","                \"labels_team2\" : [f\"{tracker_id}\" for tracker_id in team2_detections.tracker_id],\n","                \"labels_referee\" : [\"ref\"] * len(referee_detections),\n","                \"labels_gk\" : [\"GK\"] * len(goalkeepers_detections)\n","                 \n","            }\n","            \n","            # Annotate the frame\n","\n","            all_detection = {\n","                 \"goalkeepers\":goalkeepers_detections,\n","                 \"ball\":ball_detections,\n","                 \"palyers\":players_detections,\n","                 \"referee\":referee_detections,\n","                 \"team1\":team1_detections,\n","                 \"team2\":team2_detections,\n","                 \"active_player\":active_player_detection\n","            }\n","            \n","            # detect pitch key points\n","\n","            result = FIELD_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n","            key_points = sv.KeyPoints.from_inference(result)\n","\n","            # project ball, players and referies on pitch\n","\n","            filter = key_points.confidence[0] > 0.5\n","            frame_reference_points = key_points.xy[0][filter]\n","            pitch_reference_points = np.array(CONFIG.vertices)[filter]\n","\n","            transformer = ViewTransformer(\n","                source=frame_reference_points,\n","                target=pitch_reference_points\n","            )\n","\n","            frame_ball_xy = ball_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n","            pitch_ball_xy = transformer.transform_points(points=frame_ball_xy)\n","\n","            players_xy = players_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n","            pitch_players_xy = transformer.transform_points(points=players_xy)\n","\n","            referees_xy = referee_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n","            pitch_referees_xy = transformer.transform_points(points=referees_xy)\n","            \n","            # visualize video game-style radar view\n","\n","            annotated_frame1 = draw_pitch(CONFIG)\n","            annotated_frame1 = draw_points_on_pitch(\n","                config=CONFIG,\n","                xy=pitch_ball_xy,\n","                face_color=sv.Color.WHITE,\n","                edge_color=sv.Color.BLACK,\n","                radius=10,\n","                pitch=annotated_frame1)\n","            annotated_frame1 = draw_points_on_pitch(\n","                config=CONFIG,\n","                xy=pitch_players_xy[players_detections.class_id == 4],\n","                face_color=sv.Color.from_hex('00BFFF'),\n","                edge_color=sv.Color.BLACK,\n","                radius=16,\n","                pitch=annotated_frame1)\n","            annotated_frame1 = draw_points_on_pitch(\n","                config=CONFIG,\n","                xy=pitch_players_xy[players_detections.class_id == 5],\n","                face_color=sv.Color.from_hex('FF1493'),\n","                edge_color=sv.Color.BLACK,\n","                radius=16,\n","                pitch=annotated_frame1)\n","            annotated_frame1 = draw_points_on_pitch(\n","                config=CONFIG,\n","                xy=pitch_referees_xy,\n","                face_color=sv.Color.from_hex('FFD700'),\n","                edge_color=sv.Color.BLACK,\n","                radius=16,\n","                pitch=annotated_frame1)\n","\n","#             sv.plot_image(annotated_frame1)\n","            \n","            \n","            annotated_frame = annotate_frames(frame,all_detection,labels,ball_posession,MODEL_CLASSES)\n","            # Write the annotated frame to the output video\n","            # Resize the pitch diagram (annotated_frame1) to match the width of the video frame\n","            frame_height, frame_width, _ = annotated_frame.shape\n","            pitch_height, pitch_width, _ = annotated_frame1.shape\n","\n","            # Center the pitch diagram horizontally with black padding\n","            padding_left = (frame_width - pitch_width) // 2\n","            padding_right = frame_width - pitch_width - padding_left\n","\n","            # Add padding to the pitch diagram (annotated_frame1)\n","            padded_pitch = cv2.copyMakeBorder(\n","                annotated_frame1, \n","                top=0, bottom=0, \n","                left=padding_left, right=padding_right, \n","                borderType=cv2.BORDER_CONSTANT, \n","                value=[0, 0, 0]  # Black color padding\n","            )\n","            \n","            combined_frame = np.vstack((annotated_frame, padded_pitch))\n","#             sv.plot_image(combined_frame)\n","            out.write(combined_frame)\n","#             print(combined_frame.shape)\n","#             if (i%10 != 0) or i<110:\n","#                 i+=1\n","#                 sv.plot_image(annotated_frame)\n","#             i+=1\n","    #     except Exception as e:\n","    #         print(f\"Error processing frame: {e}\")\n","    #         continue\n","            # break\n","    # Release resources\n","    out.release()\n","    # cv2.destroyAllWindows()\n","\n","    print(f\"Video saved as {OUT_VIDEO}\")\n","\n","if __name__ == '__main__':\n","    main()"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5598475,"sourceId":9253518,"sourceType":"datasetVersion"}],"dockerImageVersionId":30762,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
